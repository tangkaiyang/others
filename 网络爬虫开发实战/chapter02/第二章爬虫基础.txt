第二章 爬虫基础
2.1 HTTP基本原理
URI: Uniform Resource Identifier,统一资源标志符
URL: Universal Resource Locator,统一资源定位符
URL是URI的子集,URI还包括一个子类叫做URN,Universal Resource Name,统一资源名称.
URN只命名资源而不指定如何定位资源
请求头中
Content-Type:text/html代表HTML格式,image/gif代表GIF图片,application/json代表JSON类型
请求体中:Content-Type设置为application/x-www-form-urlencoded,才会以表单数据的形式提交
application/json来提交JSON数据,multipart/form-data来上传文件,text/xml,提交XML数据
在爬虫中,如果要构造POST请求,需要使用正确的Content-Type,并了解各种请求库的各个参数设置时使用的是哪种
Content-Type,不然可能导致POST提交后无法正常响应
响应头中Content-Type:text/html为返回HTML文档,application/x-javascript则代表返回JavaScript文件,
image/jpeg代表返回图片
响应体:
响应的正文数据都在响应体中,比如请求网页时,它的响应体就是网页的HTML代码;
请求一张图片时,它的响应体就是图片的二进制数据
做爬虫请求网页后,要解析的内容就是响应体.
在做爬虫时,我们主要通过响应体得到网页的源代码,JSON数据等,然后从中做相应内容的提取
2.2网页基础
网页可以分为三大部分--HTML,CSS和JavaScript
HTML中,不同类型的文字通过不同类型的标签来表示,如图片用img标签表示,视频用video标签表示,段落用p标签表示,
他们之间的布局又常通过布局标签div嵌套组合而成
CSS,层叠样式表."层叠"指当HTML中引用了数个样式文件,并且样式发生冲突时,浏览器能依据层叠顺序处理.
"样式"指网页中文字大小,颜色,元素间距,排列等样式,CSS是目前唯一的网页页面排版样式标准.
格式:
#id.class.class{
    position:元素的布局方式;
    bottom:下边距;
    width:宽度;
    height:高度;
}
在网页中,一般会统一定义整个网页的样式规则,并写入CSS文件中(其后缀为css).
在HTML中,只需要用link标签即可引入写好的CSS文件.
JavaScript,JS,一种脚本语言.HTML和CSS配合使用,提供个用户的只是一种静态信息,缺乏交互性.
我们在网页里可能看到一些交互和动画效果,如下载进度条,提示框,轮播图等,都是JavaScript的功劳
它的出现使得用户与信息之间不只是一种浏览和显示的关系,而是实现了一种实时,动态,交互的页面功能
JavaScript通常也是以单独的文件形式加载的,后缀为js,
在HTML中通过script标签即可引入,<script src=".....js"></script>
综上,HTML定义了网页的内容和结构,CSS描述了网页的布局,JavaScript定义了网页的行为
DOCTYPE定义了文档类型,其次最外层是html标签,最后还有对应的结束标签表示闭合,内部是head标签和body标签,分别代表网页头和网页体.
他们也需要结束标签.head标签内定义了一些页面的配置和引用.如:
    <meta charset="UTF-8">
它制定了网页的编码为UTF-8
title标签定义了网页的标题,会显示在网页的选项卡中,不会显示在正文中.
body标签内侧是网页正文中显示的内容.div标签定义了网页中的区块,它的id是container,这是一个非常非常有用的属性,
且id的内容在网页中是唯一的,我们可以通过它来获取这个区块.然后在此区块内又有一个div标签,它的class为wrapper,这也是一个非常
非常有用的属性,经常与CSS配合使用来设定样式.然后此区块内部又有一个h2标签,这代表一个二级标题.另外,还有一个p标签,
这代表一个段落.在这两者中直接写入相应的内容即可在网页中呈现出来,他们也有各自的class属性
一个网页的标准形式是html标签内嵌套head和body标签,head内定义网页的配置和引用,body内定义网页的正文
2.2.3 节点树及节点间的关系
在HTML中,所有标签定义的内容都是节点,构成了HTML DOM树
DOM是W3C的标准,Document Object Model,即文档对象模型.定义了访问HTML和XML文档的标准
DOM中立与平台和语言的接口,允许程序和脚本动态地访问和更新文档地内容,结构和样式
W3C DOM标准被分为3个不同地不分:
# 核心DOM:针对任何结构化文档地标准模型
# XML DOM:针对XML文档地标准模型
# HTML DOM:针对HTML文档地标准模型
根据HTML DOM标准,HTML文档中地所有内容都是节点.
# 整个文档是一个文档节点
# 每个HTML元素是元素节点
# HTML元素内的文本是文本节点
# 每个HTML属性是属性节点
# 注释是注释节点
HTML文档被视作树结构,称为节点树
通过HTML DOM,树中的所有节点均可通过JavaScript访问,所有HTML节点元素均可被修改，也可以被创建或删除
节点树中的节点彼此拥有层级关系．我们常用父(parent),子(child)和兄弟(sibling)等术语描述这些关系.父节点拥有子节点,同级的子节点被称为兄弟节点
在节点树中,顶端节点称为根(root).除了根节点之外,每个节点都有父节点,同时可拥有任意数量的子节点或兄弟节点.
2.2.4 选择器
CSS选择器会根据不同的节点设置不同的样式规则,
如何定位节点?在CSS中我们使用CSS选择器来选择定位节点.
例如,上例中div节点的id为container,那么就可以表示为#container,其中#开头代表id,其后紧跟id的名称.
另外,如果我们想选择class为wrapper的节点,便可以使用.wrapper,这里以点(.)开头代表选择class,其后紧跟class的名称.
另外,还有一种选择方式,那就是根据标签名筛选,例如想选择二级标题,直接用h2即可.
这是常用的3种表示,分别是根据id,class,标签名筛选.
另外,CSS还支持嵌套选择,各个选择器之间加上空格分隔开便可以代表嵌套关系,如#container .wrapper p则代表先选择id为container的节点,
然后选中其内部的class为wrapper的节点,然后再进一步选中其内部的p节点.另外,如果不加空格,则代表并列关系,如div#container .wrapperp.text
代表先选择id为container的div节点,然后选中其内部的class为wrapper的节点,再进一步选中其内部的class为text的p节点.
另外还有一种比较常用的选择器是XPath,
2.3 爬虫的基本原理
2.3.1 爬虫概述
简单来说,爬虫就是获取网页并提取和保存信息的自动化程序
1.获取网页
urllib,requests等库实现HTTP请求操作
2.提取信息
正则表达式(复杂),根据网页节点属性,CSS选择器或XPath来提取网页信息的库,如Beautiful Soup,pyquery,lxml等.
3.保存数据
4.自动化程序
爬虫代替我们完成这份爬取工作的自动化程序,他可以在抓取过程中进行各种异常处理,错误重试等操作,确保爬取持续高效地运行

2.3.3 JavaScript渲染页面
有时候用urllib或requests抓取网页时,得到地源代码实际和浏览器中看到地不一样.这是非常常见地问题.
现在网页越来越多地采用Ajax,前端模块化工具来构建,整个网页可能都是由JavaScript渲染出来的,原始的HTML代码就是一个空壳
在浏览器中打开这个页面时,首先会加载这个HTML内容,接着浏览器会发现其中引入了一个app.js文件,然后便会接着取请求这个文件,
获取到该文件后,便会执行其中的JavaScript代码,而JavaScript则会改变HTML中的节点，向其添加内容，最后得到完整的页面．
但是，在用urllib或requests等库请求当前页面时,我们得到的只是这个HTML代码,他不会帮助我们取继续加载这个JavaScript文件,这样也就
看不到浏览器中的内容.因此,使用基本的HTTP请求库得到的源代码可能跟浏览器中的页面源代码不太一样.
对于这样的情况,我们可以分析其后台Ajax接口,也可以使用Selenium,Splash这样的库来实现模拟JavaScript渲染.
2.4 会话和Cookies
会话(Session)
2.4.1 静态网页和动态网页
动态网页,可以动态解析URL中参数的变化,关联数据库并动态呈现不同的页面内容,非常灵活多变.
动态网站还可以实现用户登录和注册功能.
2.4.2 无状态HTTP
拥有保持HTTP连接状态的技术:会话和Cookies.
会话在服务端,用来保存用户的会话信息;
Cookies在客户端,
因此在爬虫中,有时候处理需要登录才能访问的页面时,我们一般会直接将登陆成功后获取的Cookies放在请求头里面直接请求,而不必重新模拟登录
会话和Cookies的原理
1.会话
会话,其本来的含义是指有始有终的一系列动作/消息.而在Web中,会话对象用来存储特定用户会话所需的属性及配置信息.这样,当用户在应用程序的Web
页之间跳转时,存储在会话对象中的变量将不会丢失,而在整个用户会话中一直存在下去.当用户请求来自应用程序的Web页时,如果该用户还没有会话,
则Web服务器将自动创建一个会话对象.当会话过期或放弃后,服务器将终止该会话.
2.Cookies
Cookies指某些网站为了辨别用户身份,进行会话跟踪而存储在用户本地终端上的数据.
#会话维持
当客户端第一次请求服务器时,服务器会返回一个请求头中带有Set-Cookie字段的响应给客户端,用来标记时哪一个用户,客户端浏览器会把Cookies
保存起来,当浏览器下一次再请求该网站时,浏览器会把此Cookies放到请求头一起提交给服务器,Cookies携带了会话ID信息,服务器检查该Cookies即可
找到对应的会话是什么,然后再判断会话来以此来辨认用户状态.
#属性结构
Cookie的属性
Name:该Cookie的名称.一旦创建,该名称便不可更改
Value:该Cookie的值.如果值为Unicode支付,需要为字符编码.如果值为二进制数据,则需要使用Base64编码
Domain:可以访问该Cookie的域名.
Max Age:该Cookie失效的时间,单位为妙,常和Expires一起使用
Path:该Cookie的使用路径.如果设置为/path/,则只有路径为/path/的页面可以访问该Cookie
Size字段:此Cookie的大小
HTTP字段:Cookie的httponly属性.
Secure:该Cookie是否仅被使用安全协议传输.
#会话Cookie和持久Cookie
严格来说没有会话Cookie和持久Cookie之分,只是由Cookie的Max Age和Expires字段决定了过期的时间
2.5代理的基本原理
服务器会检测某个IP再单位时间内的请求次数,如果超过了某个阈值,就会直接拒绝服务,返回一些错误信息,这种情况可以称为封IP
一种有效的方式来伪装我们的IP是使用代理
2.5.1 基本原理
代理实际上指的是代理服务器,proxy server,它的功能是代理网络用户取取得网络信息.
2.5.2 代理的作用
#突破自身IP访问限制,访问一些平时不能访问的站点
#访问一些单位或团体内部资源:比如使用教育网内地址段免费代理服务器,就可以拥有对教育网开放的各类FTP下载上传,以及各类资料查询共享等服务
#提高访问速度:通常代理服务器都设置一个较大的硬盘缓冲区,当有外界的信息通过时,同时也将其保存到缓冲区中,当其他用户再访问相同的信息时,
则直接由缓冲区中取出信息,传给用户,以提高访问速度
#隐藏真实IP:上网者也可以通过这种方法隐藏自己的IP,免受攻击.对于爬虫来说,我们用代理就是为了隐藏自身IP,防止自身的IP被封
2.5.5 常见代理设置
免费或付费代理
ADSL拨号:拨一次号换一次IP,稳定性高,也是一种比较有效的解决方案
